{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LoadingBMWDataset import ObjectDetectionDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_annotations_to_yolo_format(img_dir, annotation_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "    # Iterating over each annotation file in the annotation directory, and convert the annotations to YOLO format\n",
    "    for annotation_file in os.listdir(annotation_dir):\n",
    "        if annotation_file.endswith('.json'):\n",
    "            json_path = os.path.join(annotation_dir, annotation_file)\n",
    "            with open(json_path) as f:\n",
    "                annotations = json.load(f)\n",
    "            \n",
    "            # Deriving the corresponding image file path and load it to get dimensions\n",
    "            img_file = annotation_file.replace('.json', '.jpg')\n",
    "            img_path = os.path.join(img_dir, img_file)\n",
    "            with Image.open(img_path) as img:\n",
    "                img_width, img_height = img.size\n",
    "            \n",
    "            # Converting annotations to YOLO format\n",
    "            yolo_annotations = []\n",
    "            for annot in annotations:\n",
    "                class_id = annot['ObjectClassId'] - 1  # Assuming class IDs start from 1, adjust if necessary\n",
    "                x_center = ((annot['Right'] + annot['Left']) / 2) / img_width\n",
    "                y_center = ((annot['Bottom'] + annot['Top']) / 2) / img_height\n",
    "                width = (annot['Right'] - annot['Left']) / img_width\n",
    "                height = (annot['Bottom'] - annot['Top']) / img_height\n",
    "                yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "            \n",
    "            # Saving converted annotations to TXT file\n",
    "            txt_path = os.path.join(output_dir, annotation_file.replace('.json', '.txt'))\n",
    "            with open(txt_path, 'w') as f:\n",
    "                f.write('\\n'.join(yolo_annotations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/home/wgt/Desktop/InMind Academy/AI_Track/Amazing_Project/inmind_amazing_project/data/Training/images'\n",
    "annotation_dir = '/home/wgt/Desktop/InMind Academy/AI_Track/Amazing_Project/inmind_amazing_project/data/Training/labels/json'\n",
    "output_dir = '/home/wgt/Desktop/InMind Academy/AI_Track/Amazing_Project/inmind_amazing_project/data/Training/labels/yolo'\n",
    "\n",
    "convert_annotations_to_yolo_format(img_dir, annotation_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "\n",
    "annotations_txt_dir = '/home/wgt/Desktop/InMind Academy/AI_Track/Amazing_Project/inmind_amazing_project/data/Training/labels/yolo'\n",
    "img_dir = '/home/wgt/Desktop/InMind Academy/AI_Track/Amazing_Project/inmind_amazing_project/data/Training/images'\n",
    "\n",
    "# Listing all .txt annotation files\n",
    "annotation_files = glob.glob(os.path.join(annotations_txt_dir, '*.txt'))\n",
    "\n",
    "# Extracting corresponding image file names from annotation file names\n",
    "img_files = [os.path.join(img_dir, os.path.basename(f).replace('.txt', '.jpg')) for f in annotation_files]\n",
    "\n",
    "# Splitting the dataset into training and validation\n",
    "train_img_files, val_img_files, train_annotation_files, val_annotation_files = train_test_split(img_files, annotation_files, test_size=0.2, random_state=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
